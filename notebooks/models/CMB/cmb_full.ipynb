{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from dataclasses import dataclass,asdict,field\n",
    "from torch.distributions import Categorical,Normal,Dirichlet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from markov_bridges.configs.config_classes.data.basics_configs import IndependentMixConfig\n",
    "from markov_bridges.data.categorical_samples import IndependentMixDataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Bridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markov_bridges.models.networks.utils.ema import EMA\n",
    "from markov_bridges.models.pipelines.thermostat_utils import load_thermostat\n",
    "from markov_bridges.configs.config_classes.generative_models.cmb_config import CMBConfig\n",
    "from markov_bridges.utils.shapes import right_shape,right_time_size,where_to_go_x\n",
    "from markov_bridges.models.pipelines.thermostats import Thermostat\n",
    "from markov_bridges.models.networks.temporal.mixed.mixed_networks_utils import load_mixed_network\n",
    "from markov_bridges.data.abstract_dataloader import MarkovBridgeDataNameTuple\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "class ConditionalForwardMap(EMA,nn.Module):\n",
    "    \"\"\"\n",
    "    This corresponds to the torch module which contains all the elements requiered to \n",
    "    sample and train a Mixed Variable Bridge\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, config:CMBConfig,device,join_context=None):\n",
    "        \"\"\"\n",
    "        join_context(context_discrete,discrete_data,context_continuous,continuuous_data)->full_discrete,full_continuous: \n",
    "        this function should allow us to create a full discrete and continuous vector from the context and data\n",
    "\n",
    "        \"\"\"\n",
    "        EMA.__init__(self,config)\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        self.config = config\n",
    "        config_data = config.data\n",
    "\n",
    "        self.vocab_size = config_data.vocab_size\n",
    "\n",
    "        self.has_context_discrete = config_data.has_context_discrete     \n",
    "        self.has_context_continuous = config_data.has_context_continuous \n",
    "\n",
    "        self.has_target_discrete = config_data.has_target_discrete \n",
    "        self.has_target_continuous = config_data.has_target_continuous \n",
    "\n",
    "        self.continuos_dimensions = config_data.continuos_dimensions\n",
    "        self.discrete_dimensions = config_data.discrete_dimensions\n",
    "    \n",
    "        self.context_discrete_dimension = config_data.context_discrete_dimension\n",
    "        self.context_continuous_dimension = config_data.context_continuous_dimension\n",
    "\n",
    "        self.join_context = join_context\n",
    "\n",
    "        self.define_deep_models(config,device)\n",
    "        self.define_bridge_parameters(config)\n",
    "        \n",
    "        self.discrete_loss_nn = nn.CrossEntropyLoss(reduction='none')\n",
    "        self.continuous_loss_nn = nn.MSELoss(reduction='none')\n",
    "\n",
    "        self.to(device)\n",
    "        self.init_ema()\n",
    "\n",
    "    def define_deep_models(self,config,device):\n",
    "        self.mixed_network = load_mixed_network(config,device=device)\n",
    "        \n",
    "    def define_bridge_parameters(self,config):\n",
    "        self.discrete_bridge_:Thermostat = load_thermostat(config)\n",
    "        self.continuous_bridge_ = None\n",
    "    #====================================================================\n",
    "    # SAMPLE BRIDGE\n",
    "    #====================================================================\n",
    "    def sample_discrete_bridge(self,x_1,x_0,time):\n",
    "        device = x_1.device\n",
    "        x_to_go = where_to_go_x(x_0,self.vocab_size)\n",
    "        transition_probs = self.telegram_bridge_probability(x_to_go, x_1, x_0, time)\n",
    "        sampled_x = Categorical(transition_probs).sample().to(device)\n",
    "        return sampled_x\n",
    "    \n",
    "    def sample_continuous_bridge(self,x_1,x_0,time):\n",
    "        \"\"\"\n",
    "        simple brownian bridge\n",
    "        \"\"\"\n",
    "        device = x_1.device\n",
    "        original_shape = x_0.shape\n",
    "        continuous_dimensions = x_1.size(1)\n",
    "        time_ = time[:,None].repeat((1,continuous_dimensions))\n",
    "\n",
    "        t = time_.flatten()\n",
    "        x_1 = x_1.flatten()\n",
    "        x_0 = x_0.flatten()\n",
    "\n",
    "        x_m = x_0*(1.-t) + x_1*t\n",
    "        variance = t*(1. - t)\n",
    "\n",
    "        x = Normal(x_m,variance).sample().to(device)\n",
    "        x = x.reshape(original_shape)\n",
    "        return x\n",
    "    \n",
    "    def sample_bridge(self,databatch):\n",
    "        time = databatch.time.flatten()\n",
    "        if self.has_target_discrete:\n",
    "            source_discrete = databatch.source_discrete.float()\n",
    "            target_discrete = databatch.target_discrete.float()\n",
    "            discrete_sample = self.sample_discrete_bridge(target_discrete,source_discrete,time)\n",
    "        else:\n",
    "            discrete_sample = None\n",
    "\n",
    "        if self.has_target_continuous:\n",
    "            source_continuous = databatch.source_continuous\n",
    "            target_continuous = databatch.target_continuous     \n",
    "            continuous_sample = self.sample_continuous_bridge(target_continuous,source_continuous,time)\n",
    "        else:\n",
    "            continuous_sample = None\n",
    "        return discrete_sample,continuous_sample\n",
    "    #====================================================================\n",
    "    # RATES AND DRIFT for GENERATION\n",
    "    #====================================================================\n",
    "    def discrete_rate(self,change_logits,x,time):\n",
    "        \"\"\"\n",
    "        RATE\n",
    "\n",
    "        :param x: [batch_size,dimensions]\n",
    "        :param time:\n",
    "        :return:[batch_size,dimensions,vocabulary_size]\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        if len(x.shape) != 2:\n",
    "            x = x.reshape(batch_size,-1)\n",
    "\n",
    "        beta_integral_ = self.beta_integral(right_time_size(1.,x), right_time_size(time))\n",
    "        w_1t = torch.exp(-self.vocab_size * beta_integral_)\n",
    "        A = 1.\n",
    "        B = (w_1t * self.vocab_size) / (1. - w_1t)\n",
    "        C = w_1t\n",
    "\n",
    "        change_classifier = softmax(change_logits, dim=2)\n",
    "\n",
    "        #x = x.reshape(batch_size,self.dimensions)\n",
    "        where_iam_classifier = torch.gather(change_classifier, 2, x.long().unsqueeze(2))\n",
    "\n",
    "        rates = A + B[:,None,None]*change_classifier + C[:,None,None]*where_iam_classifier\n",
    "        return rates\n",
    "    \n",
    "    def continuous_drift(self,x,t):\n",
    "        return None\n",
    "    \n",
    "    def forward_map(self,databatch:MarkovBridgeDataNameTuple):\n",
    "        discrete_head, continuous_head = self.mixed_network(databatch)\n",
    "        return None\n",
    "    #====================================================================\n",
    "    # LOSS\n",
    "    #====================================================================\n",
    "    def loss(self,databatch:MarkovBridgeDataNameTuple,discrete_sample,continuous_sample):\n",
    "        # IF WE HAVE CONTEXT JOIN FOR FULL DATA\n",
    "        if self.has_context_continuous:\n",
    "            context_continuous = databatch.context_continuous\n",
    "        else:\n",
    "            context_continuous = None\n",
    "            \n",
    "        if self.has_context_discrete:\n",
    "            context_discrete = databatch.context_discrete\n",
    "        else:\n",
    "            context_discrete = None\n",
    "\n",
    "        discrete_sample,continuous_sample = self.join_context(context_discrete,\n",
    "                                                              discrete_sample,\n",
    "                                                              context_continuous,\n",
    "                                                              continuous_sample)\n",
    "        \n",
    "        # Calculate Heads For Classifier or Mean Average\n",
    "        discrete_head,continuous_head = self.mixed_network(discrete_sample,continuous_sample,databatch.time)\n",
    "        \n",
    "        # Train What is Needed\n",
    "        full_loss = torch.Tensor([0.])\n",
    "        \n",
    "        if self.has_target_discrete:\n",
    "            full_loss += self.discrete_loss(databatch,discrete_head).mean()\n",
    "\n",
    "        if self.has_target_continuous:\n",
    "            full_loss += self.continuous_loss(databatch,continuous_head).mean()\n",
    "\n",
    "        return full_loss\n",
    "    \n",
    "    def discrete_loss(self,databatch:MarkovBridgeDataNameTuple,discrete_head):\n",
    "        # If has context remove the part predicting context\n",
    "        if self.has_context_discrete:\n",
    "            discrete_head = discrete_head[:, self.context_discrete_dimension:,:]\n",
    "        \n",
    "        # reshape for cross logits\n",
    "        discrete_head = discrete_head.reshape(-1, self.config.data.vocab_size)\n",
    "        target_discrete = databatch.target_discrete.reshape(-1)\n",
    "        discrete_loss = self.discrete_loss_nn(discrete_head,target_discrete.long())\n",
    "        return discrete_loss\n",
    "    \n",
    "    def continuous_loss(self,databatch:MarkovBridgeDataNameTuple,continuous_head):\n",
    "        # If has context continuous\n",
    "        if self.has_context_continuous:\n",
    "            continuous_head = continuous_head[:, self.context_continuous_dimension:,:]\n",
    "        mse = self.continuous_loss_nn(continuous_head,databatch.target_continuous)\n",
    "        return mse\n",
    "    #====================================================================\n",
    "    # DISCRETE BRIDGE FUNCTIONS\n",
    "    #====================================================================\n",
    "    def multivariate_telegram_conditional(self,x, x0, t, t0):\n",
    "        \"\"\"\n",
    "        \\begin{equation}\n",
    "        P(x(t) = i|x(t_0)) = \\frac{1}{s} + w_{t,t_0}\\left(-\\frac{1}{s} + \\delta_{i,x(t_0)}\\right)\n",
    "        \\end{equation}\n",
    "\n",
    "        \\begin{equation}\n",
    "        w_{t,t_0} = e^{-S \\int_{t_0}^{t} \\beta(r)dr}\n",
    "        \\end{equation}\n",
    "\n",
    "        \"\"\"\n",
    "        t = right_time_size(x,t).to(x0.device)\n",
    "        t0 = right_time_size(x,t0).to(x0.device)\n",
    "\n",
    "        integral_t0 = self.discrete_bridge_.beta_integral(t, t0)\n",
    "        w_t0 = torch.exp(-self.vocab_size * integral_t0)\n",
    "\n",
    "        x = right_shape(x)\n",
    "        x0 = right_shape(x0)\n",
    "\n",
    "        delta_x = (x == x0).float()\n",
    "        probability = 1. / self.vocab_size + w_t0[:, None, None] * ((-1. / self.vocab_size) + delta_x)\n",
    "        return probability\n",
    "\n",
    "    def telegram_bridge_probability(self,x,x1,x0,t):\n",
    "        \"\"\"\n",
    "        \\begin{equation}\n",
    "        P(x_t=x|x_0,x_1) = \\frac{p(x_1|x_t=x) p(x_t = x|x_0)}{p(x_1|x_0)}\n",
    "        \\end{equation}\n",
    "        \"\"\"\n",
    "        P_x_to_x1 = self.multivariate_telegram_conditional(x1, x, t=1., t0=t)\n",
    "        P_x0_to_x = self.multivariate_telegram_conditional(x, x0, t=t, t0=0.)\n",
    "        P_x0_to_x1 = self.multivariate_telegram_conditional(x1, x0, t=1., t0=0.)\n",
    "        conditional_transition_probability = (P_x_to_x1 * P_x0_to_x) / P_x0_to_x1\n",
    "        return conditional_transition_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = CMBConfig()\n",
    "model_config.data = IndependentMixConfig()\n",
    "dataloader = IndependentMixDataloader(model_config.data)\n",
    "databatch = dataloader.get_databatch()\n",
    "cfm = ConditionalForwardMap(model_config,device=torch.device(\"cpu\"),join_context=dataloader.join_context)\n",
    "discrete_sample,continuous_sample = cfm.sample_bridge(databatch)\n",
    "cfm.loss(databatch,discrete_sample,continuous_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discrete_head,continuous_head = cfm.mixed_network(discrete_sample,continuous_sample,databatch.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.4774], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm.loss(databatch,discrete_sample,continuous_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_sample[:,:,None].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rate_matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
