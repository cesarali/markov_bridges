{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import markov_bridges.data.qm9.utils as qm9utils\n",
    "\n",
    "from markov_bridges.configs.config_classes.data.molecules_configs import QM9Config\n",
    "from markov_bridges.data.dataloaders_utils import get_dataloaders\n",
    "from markov_bridges.configs.experiments_configs.mixed.edmg_experiments import get_edmg_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_edmg_experiment()\n",
    "config.data = QM9Config(datadir = \"qm9_dataset_from_notebook\", #lp set this, also added this folder to .gitignore\n",
    "                        num_pts_train=1000,\n",
    "                        num_pts_test=200,\n",
    "                        num_pts_valid=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piazza/.conda/envs/ML_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditioning on ['H_thermo', 'homo']\n"
     ]
    }
   ],
   "source": [
    "dataloaders = get_dataloaders(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_atoms',\n",
       " 'charges',\n",
       " 'positions',\n",
       " 'index',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'mu',\n",
       " 'alpha',\n",
       " 'homo',\n",
       " 'lumo',\n",
       " 'gap',\n",
       " 'r2',\n",
       " 'zpve',\n",
       " 'U0',\n",
       " 'U',\n",
       " 'H',\n",
       " 'G',\n",
       " 'Cv',\n",
       " 'omega1',\n",
       " 'zpve_thermo',\n",
       " 'U0_thermo',\n",
       " 'U_thermo',\n",
       " 'H_thermo',\n",
       " 'G_thermo',\n",
       " 'Cv_thermo']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders.get_databach_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piazza/.conda/envs/ML_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "databatch = dataloaders.get_databatch()\n",
    "#self.dtype = torch.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = qm9utils.prepare_context(config.noising_model.conditioning, \n",
    "                                   databatch, \n",
    "                                   dataloaders.property_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 25, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 25, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databatch[\"charges\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'qm9',\n",
       " 'atom_encoder': {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4},\n",
       " 'atom_decoder': ['H', 'C', 'N', 'O', 'F'],\n",
       " 'n_nodes': {22: 3393,\n",
       "  17: 13025,\n",
       "  23: 4848,\n",
       "  21: 9970,\n",
       "  19: 13832,\n",
       "  20: 9482,\n",
       "  16: 10644,\n",
       "  13: 3060,\n",
       "  15: 7796,\n",
       "  25: 1506,\n",
       "  18: 13364,\n",
       "  12: 1689,\n",
       "  11: 807,\n",
       "  24: 539,\n",
       "  14: 5136,\n",
       "  26: 48,\n",
       "  7: 16,\n",
       "  10: 362,\n",
       "  8: 49,\n",
       "  9: 124,\n",
       "  27: 266,\n",
       "  4: 4,\n",
       "  29: 25,\n",
       "  6: 9,\n",
       "  5: 5,\n",
       "  3: 1},\n",
       " 'max_n_nodes': 29,\n",
       " 'atom_types': {1: 635559, 2: 101476, 0: 923537, 3: 140202, 4: 2323},\n",
       " 'distances': [903054,\n",
       "  307308,\n",
       "  111994,\n",
       "  57474,\n",
       "  40384,\n",
       "  29170,\n",
       "  47152,\n",
       "  414344,\n",
       "  2202212,\n",
       "  573726,\n",
       "  1490786,\n",
       "  2970978,\n",
       "  756818,\n",
       "  969276,\n",
       "  489242,\n",
       "  1265402,\n",
       "  4587994,\n",
       "  3187130,\n",
       "  2454868,\n",
       "  2647422,\n",
       "  2098884,\n",
       "  2001974,\n",
       "  1625206,\n",
       "  1754172,\n",
       "  1620830,\n",
       "  1710042,\n",
       "  2133746,\n",
       "  1852492,\n",
       "  1415318,\n",
       "  1421064,\n",
       "  1223156,\n",
       "  1322256,\n",
       "  1380656,\n",
       "  1239244,\n",
       "  1084358,\n",
       "  981076,\n",
       "  896904,\n",
       "  762008,\n",
       "  659298,\n",
       "  604676,\n",
       "  523580,\n",
       "  437464,\n",
       "  413974,\n",
       "  352372,\n",
       "  291886,\n",
       "  271948,\n",
       "  231328,\n",
       "  188484,\n",
       "  160026,\n",
       "  136322,\n",
       "  117850,\n",
       "  103546,\n",
       "  87192,\n",
       "  76562,\n",
       "  61840,\n",
       "  49666,\n",
       "  43100,\n",
       "  33876,\n",
       "  26686,\n",
       "  22402,\n",
       "  18358,\n",
       "  15518,\n",
       "  13600,\n",
       "  12128,\n",
       "  9480,\n",
       "  7458,\n",
       "  5088,\n",
       "  4726,\n",
       "  3696,\n",
       "  3362,\n",
       "  3396,\n",
       "  2484,\n",
       "  1988,\n",
       "  1490,\n",
       "  984,\n",
       "  734,\n",
       "  600,\n",
       "  456,\n",
       "  482,\n",
       "  378,\n",
       "  362,\n",
       "  168,\n",
       "  124,\n",
       "  94,\n",
       "  88,\n",
       "  52,\n",
       "  44,\n",
       "  40,\n",
       "  18,\n",
       "  16,\n",
       "  8,\n",
       "  6,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'colors_dic': ['#FFFFFF99', 'C7', 'C0', 'C3', 'C1'],\n",
       " 'radius_dic': [0.46, 0.77, 0.77, 0.77, 0.77],\n",
       " 'with_h': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders.dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lisa test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piazza/.conda/envs/ML_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_atoms': tensor([17, 19, 16, 16, 15, 21, 21, 20, 19, 18, 18, 19, 16, 14, 22, 15, 21, 19,\n",
       "         19, 20, 23, 19, 17, 19, 20, 21, 16, 13, 19, 16, 23, 10]),\n",
       " 'charges': tensor([[[8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [9],\n",
       "          [7],\n",
       "          [7],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [7],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [7],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[7],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [7],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0]],\n",
       " \n",
       "         [[8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [7],\n",
       "          [7],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1]],\n",
       " \n",
       "         [[8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [8],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[8],\n",
       "          [6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1]],\n",
       " \n",
       "         [[9],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [8],\n",
       "          [7],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]]),\n",
       " 'positions': tensor([[[ 8.2234e-02,  1.4345e+00,  2.8389e-01],\n",
       "          [-3.9521e-03,  5.1693e-02, -2.4211e-02],\n",
       "          [-1.4241e+00, -4.3091e-01,  3.7067e-02],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[ 2.4181e-01,  1.3206e+00,  1.5566e-01],\n",
       "          [-1.8073e-01,  2.5549e-02, -1.9682e-01],\n",
       "          [ 6.9691e-01, -6.1051e-01, -1.0980e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[-2.1592e-01, -1.2695e+00, -1.3970e-01],\n",
       "          [-1.1903e-01, -7.4348e-02, -4.9663e-02],\n",
       "          [-1.9267e-03,  1.3612e+00,  6.4831e-02],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.5921e-01,  1.3364e+00, -3.6980e-01],\n",
       "          [ 9.0500e-03, -3.8385e-03, -7.6502e-02],\n",
       "          [-3.8294e-01, -9.8410e-01, -1.1645e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[-3.2739e-01,  1.4458e+00,  2.2240e-02],\n",
       "          [ 6.8091e-02, -2.7906e-02,  8.2904e-02],\n",
       "          [ 7.1569e-01, -5.7528e-01, -1.2103e+00],\n",
       "          ...,\n",
       "          [ 1.2933e+00, -3.8846e+00,  1.2167e+00],\n",
       "          [ 1.9184e+00,  3.6258e-01,  1.1414e+00],\n",
       "          [ 6.7989e-01, -3.3929e-01,  2.1825e+00]],\n",
       " \n",
       "         [[ 5.7018e-02,  4.0873e-02,  2.3377e-03],\n",
       "          [-2.2873e-02,  1.3608e+00,  1.0782e-02],\n",
       "          [-1.1949e+00,  2.0151e+00,  3.0199e-02],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]),\n",
       " 'index': tensor([106031, 122473,  34960,   3447, 133169, 103515,  38966,  62219,  83708,\n",
       "         126393,  12927, 120596,  34045,   6239, 122903,  12724,  62493, 117451,\n",
       "         122405, 124483, 114817,  50007,  41624,  80631,  81285, 112706,  80320,\n",
       "          42640,  52702,  12995,  92501,  23802]),\n",
       " 'A': tensor([2.7277, 3.6119, 3.2787, 4.4623, 3.2165, 2.7768, 2.9764, 4.6264, 2.4508,\n",
       "         3.4026, 3.3976, 3.8747, 3.2033, 4.5997, 5.0350, 3.0196, 2.0539, 5.9190,\n",
       "         5.2025, 2.4872, 2.5418, 3.6293, 3.4726, 2.7486, 2.7034, 2.3589, 3.5925,\n",
       "         2.8526, 3.9908, 2.8058, 2.6299, 4.0305]),\n",
       " 'B': tensor([1.5810, 0.7050, 1.6001, 2.8865, 1.3547, 1.3764, 1.6296, 0.5670, 1.6832,\n",
       "         1.1135, 1.6902, 0.7740, 1.3702, 1.2659, 0.5569, 2.2383, 1.4049, 0.6096,\n",
       "         0.6414, 1.2734, 1.2925, 1.0249, 1.6240, 1.5716, 1.5439, 1.2855, 1.1428,\n",
       "         1.7289, 0.6696, 2.5559, 1.3498, 1.8776]),\n",
       " 'C': tensor([1.2364, 0.6314, 1.5298, 2.1196, 0.9590, 1.3146, 1.3415, 0.5538, 1.2264,\n",
       "         0.8924, 1.4001, 0.7213, 1.1783, 0.9987, 0.5185, 1.7121, 1.1645, 0.5690,\n",
       "         0.6046, 1.0387, 1.1363, 0.9501, 1.3700, 1.2490, 1.2524, 1.1013, 1.1099,\n",
       "         1.3093, 0.6379, 1.5910, 1.1194, 1.2809]),\n",
       " 'mu': tensor([3.1681, 1.1452, 0.8561, 2.7391, 4.9072, 0.9235, 1.7309, 3.3850, 3.1573,\n",
       "         1.9340, 1.1223, 3.7053, 2.5473, 1.0130, 4.0680, 3.1382, 0.8072, 5.8378,\n",
       "         3.6984, 4.7113, 0.9569, 3.3231, 2.8319, 1.8633, 3.4147, 3.6188, 4.0592,\n",
       "         4.9547, 4.1552, 2.6721, 1.8739, 3.9222]),\n",
       " 'alpha': tensor([71.9400, 79.7000, 73.5800, 60.3800, 75.1900, 83.8000, 80.2200, 84.0200,\n",
       "         74.1100, 75.2100, 68.1300, 78.9000, 69.2400, 70.0800, 84.7900, 61.4100,\n",
       "         86.6700, 74.5400, 73.6000, 81.2800, 86.0300, 82.3000, 73.9600, 80.4000,\n",
       "         80.4000, 74.5600, 77.4900, 66.8100, 82.3900, 64.8000, 84.7100, 52.3200]),\n",
       " 'homo': tensor([-6.5525, -6.9362, -5.9239, -6.4709, -5.7062, -6.2695, -6.9226, -6.6151,\n",
       "         -6.5035, -6.2586, -6.4491, -7.2736, -7.5212, -7.1185, -7.3580, -6.5743,\n",
       "         -6.1770, -7.1974, -7.1103, -6.4382, -6.5634, -6.6042, -6.5062, -6.6260,\n",
       "         -6.8246, -6.5226, -6.7375, -7.4722, -6.4763, -6.5906, -6.5471, -7.6464]),\n",
       " 'lumo': tensor([ 0.0354,  0.5225,  0.6014,  2.0517, -0.8408,  0.3456,  2.2477,  0.7510,\n",
       "         -0.5279,  0.8762,  2.2341,  0.4218,  0.5143, -1.3687,  1.0123,  0.4054,\n",
       "          1.3823, -0.9197,  0.2830,  0.1796,  2.2123, -0.4708, -0.0735,  1.3660,\n",
       "          0.9742,  1.6164, -1.4395, -0.8027, -0.3238, -0.5796,  2.0436, -2.5633]),\n",
       " 'gap': tensor([6.5852, 7.4559, 6.5253, 8.5253, 4.8654, 6.6178, 9.1702, 7.3661, 5.9756,\n",
       "         7.1321, 8.6832, 7.6981, 8.0355, 5.7498, 8.3702, 6.9770, 7.5593, 6.2777,\n",
       "         7.3933, 6.6178, 8.7757, 6.1334, 6.4328, 7.9920, 7.7988, 8.1389, 5.2981,\n",
       "         6.6695, 6.1525, 6.0110, 8.5906, 5.0831]),\n",
       " 'r2': tensor([1035.1259, 1781.0503,  917.2986,  660.9969, 1151.0081, 1120.2510,\n",
       "         1032.4139, 1996.7249, 1062.9397, 1331.8409,  953.7030, 1612.6522,\n",
       "         1047.5745, 1105.8785, 2149.3003,  794.6251, 1211.7189, 1932.9769,\n",
       "         1830.6375, 1262.2195, 1247.4117, 1285.8082,  956.0923, 1061.7921,\n",
       "         1085.2928, 1223.4642, 1125.9265,  928.4176, 1820.1105,  814.9319,\n",
       "         1226.1648,  814.2843]),\n",
       " 'zpve': tensor([3706.7644, 4240.5703, 3393.6155, 3767.2004, 3082.4531, 4948.2568,\n",
       "         5077.4565, 4585.1753, 4345.7969, 4034.6343, 4153.5752, 4284.2173,\n",
       "         3428.5549, 2879.2112, 5223.7998, 3245.5854, 4843.0581, 4235.5635,\n",
       "         4293.1699, 4646.1021, 5582.7456, 4335.9189, 3752.6426, 4336.2456,\n",
       "         4718.7290, 4956.3662, 3410.6770, 2444.3186, 4211.7808, 3564.8567,\n",
       "         5616.0791, 1622.1532]),\n",
       " 'U0': tensor([-11477.4600, -11509.1914, -10901.7324,  -8864.2812, -12465.8125,\n",
       "         -10532.8672, -10533.7021, -10970.0410, -11511.6064, -11845.4365,\n",
       "         -10473.4473, -11406.5752, -11915.2861, -10305.6504, -11003.4150,\n",
       "         -10879.1719, -10532.3047, -12522.8184, -12522.1768, -10866.8643,\n",
       "         -10565.1660, -10500.9170, -11476.6230, -10499.1602, -10970.5400,\n",
       "         -12554.4688, -10905.1953, -11308.2832, -11510.9814, -10442.6621,\n",
       "         -10566.1289, -12478.0625]),\n",
       " 'U': tensor([-11477.2461, -11508.9170, -10901.5459,  -8864.1104, -12465.5957,\n",
       "         -10532.6250, -10533.5088, -10969.7510, -11511.3838, -11845.1836,\n",
       "         -10473.2227, -11406.2998, -11915.0830, -10305.4219, -11003.1123,\n",
       "         -10878.9775, -10532.0127, -12522.5352, -12521.9189, -10866.5996,\n",
       "         -10564.9102, -10500.6943, -11476.4404, -10498.9414, -10970.3271,\n",
       "         -12554.2100, -10904.9844, -11308.0986, -11510.6758, -10442.4717,\n",
       "         -10565.8848, -12477.9004]),\n",
       " 'H': tensor([-11477.2207, -11508.8916, -10901.5205,  -8864.0850, -12465.5703,\n",
       "         -10532.6006, -10533.4834, -10969.7256, -11511.3584, -11845.1582,\n",
       "         -10473.1973, -11406.2744, -11915.0576, -10305.3965, -11003.0859,\n",
       "         -10878.9521, -10531.9873, -12522.5098, -12521.8936, -10866.5732,\n",
       "         -10564.8848, -10500.6689, -11476.4150, -10498.9160, -10970.3008,\n",
       "         -12554.1846, -10904.9590, -11308.0723, -11510.6504, -10442.4463,\n",
       "         -10565.8584, -12477.8750]),\n",
       " 'G': tensor([-11478.3682, -11510.1777, -10902.5801,  -8865.0928, -12466.6992,\n",
       "         -10533.7764, -10534.5576, -10971.0508, -11512.5088, -11846.3857,\n",
       "         -10474.3301, -11407.5488, -11916.1553, -10306.5586, -11004.4355,\n",
       "         -10880.0225, -10533.2441, -12523.8291, -12523.1465, -10867.8545,\n",
       "         -10566.0938, -10501.8203, -11477.4688, -10500.0371, -10971.4150,\n",
       "         -12555.4053, -10906.0723, -11309.1367, -11512.0283, -10443.5059,\n",
       "         -10567.0400, -12478.8896]),\n",
       " 'Cv': tensor([29.6520, 35.3420, 27.5730, 24.0810, 29.7160, 34.5180, 29.4500, 36.9220,\n",
       "         30.8290, 32.8320, 30.5990, 35.2830, 28.3330, 29.6520, 38.3310, 27.1010,\n",
       "         40.6390, 35.2230, 33.0380, 34.6890, 35.8430, 31.2660, 26.4690, 32.0290,\n",
       "         31.1100, 35.8130, 29.5810, 25.7390, 37.9730, 27.4900, 34.9350, 21.8800]),\n",
       " 'omega1': tensor([3799.8867, 3501.8369, 3502.1118, 3498.0559, 3662.3330, 3226.0315,\n",
       "         3142.2229, 3507.1431, 3126.2388, 3806.9229, 3791.2871, 3512.3567,\n",
       "         3245.5857, 3598.5198, 3150.2070, 3807.3684, 3792.3599, 3107.8630,\n",
       "         3147.0596, 3655.3093, 3126.9951, 3212.1155, 3192.7886, 3505.4443,\n",
       "         3458.2961, 3826.4861, 3778.7798, 3249.3621, 3811.4312, 3706.3914,\n",
       "         3095.2744, 3235.4504]),\n",
       " 'zpve_thermo': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64),\n",
       " 'U0_thermo': tensor([-419.0587, -420.0593, -398.0778, -323.3848, -455.7058, -383.8420,\n",
       "         -383.8420, -400.0788, -420.0593, -432.5525, -382.2125, -416.3157,\n",
       "         -435.2956, -376.4678, -401.0794, -397.4488, -383.8420, -457.2771,\n",
       "         -457.2771, -396.3352, -384.8426, -382.8415, -419.0587, -382.8415,\n",
       "         -400.0788, -458.2776, -398.0778, -413.3140, -420.0593, -381.2120,\n",
       "         -384.8426, -456.8194], dtype=torch.float64),\n",
       " 'U_thermo': tensor([-419.0347, -420.0324, -398.0551, -323.3621, -455.6846, -383.8123,\n",
       "         -383.8123, -400.0505, -420.0324, -432.5270, -382.1870, -416.2888,\n",
       "         -435.2729, -376.4480, -401.0482, -397.4275, -383.8123, -457.2502,\n",
       "         -457.2502, -396.3069, -384.8100, -382.8146, -419.0347, -382.8146,\n",
       "         -400.0505, -458.2479, -398.0551, -413.2956, -420.0324, -381.1893,\n",
       "         -384.8100, -456.8052], dtype=torch.float64),\n",
       " 'H_thermo': tensor([-419.0186, -420.0144, -398.0400, -323.3470, -455.6704, -383.7925,\n",
       "         -383.7925, -400.0316, -420.0144, -432.5100, -382.1700, -416.2708,\n",
       "         -435.2578, -376.4347, -401.0275, -397.4134, -383.7925, -457.2322,\n",
       "         -457.2322, -396.2880, -384.7883, -382.7966, -419.0186, -382.7966,\n",
       "         -400.0316, -458.2281, -398.0400, -413.2833, -420.0144, -381.1742,\n",
       "         -384.7883, -456.7958], dtype=torch.float64),\n",
       " 'G_thermo': tensor([-419.2757, -420.2976, -398.2841, -323.5834, -455.9024, -384.1012,\n",
       "         -384.1012, -400.3278, -420.2976, -432.7812, -382.4362, -416.5545,\n",
       "         -435.5024, -376.6495, -401.3497, -397.6410, -384.1012, -457.5158,\n",
       "         -457.5158, -396.5848, -385.1230, -383.0793, -419.2757, -383.0793,\n",
       "         -400.3278, -458.5376, -398.2841, -413.4889, -420.2976, -381.4144,\n",
       "         -385.1230, -456.9586], dtype=torch.float64),\n",
       " 'Cv_thermo': tensor([50.6770, 56.6390, 47.6960, 47.6960, 44.7150, 62.6010, 62.6010, 59.6200,\n",
       "         56.6390, 53.6580, 53.6580, 56.6390, 47.6960, 41.7340, 65.5820, 44.7150,\n",
       "         62.6010, 56.6390, 56.6390, 59.6200, 68.5630, 56.6390, 50.6770, 56.6390,\n",
       "         59.6200, 62.6010, 47.6960, 38.7530, 56.6390, 47.6960, 68.5630, 29.8100],\n",
       "        dtype=torch.float64),\n",
       " 'one_hot': tensor([[[False, False, False,  True, False],\n",
       "          [False,  True, False, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          ...,\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False]],\n",
       " \n",
       "         [[False,  True, False, False, False],\n",
       "          [False, False, False,  True, False],\n",
       "          [False,  True, False, False, False],\n",
       "          ...,\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False]],\n",
       " \n",
       "         [[False,  True, False, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          ...,\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[False, False, False,  True, False],\n",
       "          [False,  True, False, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          ...,\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False]],\n",
       " \n",
       "         [[False,  True, False, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          ...,\n",
       "          [ True, False, False, False, False],\n",
       "          [ True, False, False, False, False],\n",
       "          [ True, False, False, False, False]],\n",
       " \n",
       "         [[False, False, False, False,  True],\n",
       "          [False,  True, False, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          ...,\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False]]]),\n",
       " 'atom_mask': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True, False, False, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True, False, False, False, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False]]),\n",
       " 'edge_mask': tensor([[False],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         ...,\n",
       "         [False],\n",
       "         [False],\n",
       "         [False]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = dataloaders.get_databatch()\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num atoms torch.Size([32])\n",
      "charges torch.Size([32, 23, 1])\n",
      "positions torch.Size([32, 23, 3])\n",
      "index torch.Size([32])\n",
      "a torch.Size([32])\n",
      "b torch.Size([32])\n",
      "c torch.Size([32])\n",
      "mu torch.Size([32])\n",
      "one_hot torch.Size([32, 23, 5])\n",
      "atom_mask torch.Size([32, 23])\n",
      "edge_mask torch.Size([16928, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"num atoms\", batch[\"num_atoms\"].shape)\n",
    "print(\"charges\" , batch[\"charges\"].shape)\n",
    "print(\"positions\", batch[\"positions\"].shape)\n",
    "print(\"index\", batch[\"index\"].shape)\n",
    "print(\"a\", batch[\"A\"].shape)\n",
    "print(\"b\", batch[\"B\"].shape)\n",
    "print(\"c\", batch[\"C\"].shape)\n",
    "print(\"mu\", batch[\"mu\"].shape)\n",
    "print(\"one_hot\", batch[\"one_hot\"].shape)\n",
    "print(\"atom_mask\", batch[\"atom_mask\"].shape)\n",
    "print(\"edge_mask\", batch[\"edge_mask\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16928"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23*23*32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hypotesis:\n",
    "- 32 molecules\n",
    "- the biggest molecule in the batch has 23 atoms, so the number of atoms per molecule has been padded to 23\n",
    "- positions is [N molecules, N atoms per mol, 3]\n",
    "- index is the number of the molecule in the entire dataset\n",
    "- one hot is the one hot encoding of each atom\n",
    "- atom mask tells which atoms for each molecule exist and which are padded atoms\n",
    "- edge mask has shape [23 * 23 * 32 , 1], which means that each molecule is reprsented as a FC graph, and they mask edges between padded atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What they call \"charges\" is actually the atomic number -> yes\n",
    "# Check using the onehot:\n",
    "\n",
    "num_atoms_0 = batch[\"num_atoms\"][0]\n",
    "charges_0 = batch[\"charges\"][0]\n",
    "positions_0 = batch[\"positions\"][0]\n",
    "one_hot_0 = batch[\"one_hot\"][0]\n",
    "atom_mask_0 =  batch[\"atom_mask\"][0]\n",
    "edge_mask_0 = batch[\"edge_mask\"][0]\n",
    "\n",
    "#atom_vocab =  {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4}\n",
    "\n",
    "#from charges retrieve indexes of 0 elements, thse should be padded atoms\n",
    "#indexes_padded_atoms =  torch.nonzero(charges_0 == 0, as_tuple=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  True, False],\n",
       "        [False,  True, False, False, False],\n",
       "        [False,  True, False, False, False],\n",
       "        [False,  True, False, False, False],\n",
       "        [False,  True, False, False, False],\n",
       "        [False,  True, False, False, False],\n",
       "        [False,  True, False, False, False],\n",
       "        [False,  True, False, False, False],\n",
       "        [False, False, False,  True, False],\n",
       "        [ True, False, False, False, False],\n",
       "        [ True, False, False, False, False],\n",
       "        [ True, False, False, False, False],\n",
       "        [ True, False, False, False, False],\n",
       "        [ True, False, False, False, False],\n",
       "        [ True, False, False, False, False],\n",
       "        [ True, False, False, False, False],\n",
       "        [ True, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8],\n",
       "        [6],\n",
       "        [6],\n",
       "        [6],\n",
       "        [6],\n",
       "        [6],\n",
       "        [6],\n",
       "        [6],\n",
       "        [8],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charges_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False, False, False])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_mask_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_atoms': tensor([17, 19, 16, 16, 15, 21, 21, 20, 19, 18, 18, 19, 16, 14, 22, 15, 21, 19,\n",
       "         19, 20, 23, 19, 17, 19, 20, 21, 16, 13, 19, 16, 23, 10]),\n",
       " 'charges': tensor([[[8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [9],\n",
       "          [7],\n",
       "          [7],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [7],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [7],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[7],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [7],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0]],\n",
       " \n",
       "         [[8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [7],\n",
       "          [7],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1]],\n",
       " \n",
       "         [[8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [8],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[8],\n",
       "          [6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [7],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1]],\n",
       " \n",
       "         [[9],\n",
       "          [6],\n",
       "          [6],\n",
       "          [6],\n",
       "          [8],\n",
       "          [8],\n",
       "          [7],\n",
       "          [6],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]]),\n",
       " 'positions': tensor([[[ 8.2234e-02,  1.4345e+00,  2.8389e-01],\n",
       "          [-3.9521e-03,  5.1693e-02, -2.4211e-02],\n",
       "          [-1.4241e+00, -4.3091e-01,  3.7067e-02],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[ 2.4181e-01,  1.3206e+00,  1.5566e-01],\n",
       "          [-1.8073e-01,  2.5549e-02, -1.9682e-01],\n",
       "          [ 6.9691e-01, -6.1051e-01, -1.0980e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[-2.1592e-01, -1.2695e+00, -1.3970e-01],\n",
       "          [-1.1903e-01, -7.4348e-02, -4.9663e-02],\n",
       "          [-1.9267e-03,  1.3612e+00,  6.4831e-02],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.5921e-01,  1.3364e+00, -3.6980e-01],\n",
       "          [ 9.0500e-03, -3.8385e-03, -7.6502e-02],\n",
       "          [-3.8294e-01, -9.8410e-01, -1.1645e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[-3.2739e-01,  1.4458e+00,  2.2240e-02],\n",
       "          [ 6.8091e-02, -2.7906e-02,  8.2904e-02],\n",
       "          [ 7.1569e-01, -5.7528e-01, -1.2103e+00],\n",
       "          ...,\n",
       "          [ 1.2933e+00, -3.8846e+00,  1.2167e+00],\n",
       "          [ 1.9184e+00,  3.6258e-01,  1.1414e+00],\n",
       "          [ 6.7989e-01, -3.3929e-01,  2.1825e+00]],\n",
       " \n",
       "         [[ 5.7018e-02,  4.0873e-02,  2.3377e-03],\n",
       "          [-2.2873e-02,  1.3608e+00,  1.0782e-02],\n",
       "          [-1.1949e+00,  2.0151e+00,  3.0199e-02],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]),\n",
       " 'index': tensor([106031, 122473,  34960,   3447, 133169, 103515,  38966,  62219,  83708,\n",
       "         126393,  12927, 120596,  34045,   6239, 122903,  12724,  62493, 117451,\n",
       "         122405, 124483, 114817,  50007,  41624,  80631,  81285, 112706,  80320,\n",
       "          42640,  52702,  12995,  92501,  23802]),\n",
       " 'A': tensor([2.7277, 3.6119, 3.2787, 4.4623, 3.2165, 2.7768, 2.9764, 4.6264, 2.4508,\n",
       "         3.4026, 3.3976, 3.8747, 3.2033, 4.5997, 5.0350, 3.0196, 2.0539, 5.9190,\n",
       "         5.2025, 2.4872, 2.5418, 3.6293, 3.4726, 2.7486, 2.7034, 2.3589, 3.5925,\n",
       "         2.8526, 3.9908, 2.8058, 2.6299, 4.0305]),\n",
       " 'B': tensor([1.5810, 0.7050, 1.6001, 2.8865, 1.3547, 1.3764, 1.6296, 0.5670, 1.6832,\n",
       "         1.1135, 1.6902, 0.7740, 1.3702, 1.2659, 0.5569, 2.2383, 1.4049, 0.6096,\n",
       "         0.6414, 1.2734, 1.2925, 1.0249, 1.6240, 1.5716, 1.5439, 1.2855, 1.1428,\n",
       "         1.7289, 0.6696, 2.5559, 1.3498, 1.8776]),\n",
       " 'C': tensor([1.2364, 0.6314, 1.5298, 2.1196, 0.9590, 1.3146, 1.3415, 0.5538, 1.2264,\n",
       "         0.8924, 1.4001, 0.7213, 1.1783, 0.9987, 0.5185, 1.7121, 1.1645, 0.5690,\n",
       "         0.6046, 1.0387, 1.1363, 0.9501, 1.3700, 1.2490, 1.2524, 1.1013, 1.1099,\n",
       "         1.3093, 0.6379, 1.5910, 1.1194, 1.2809]),\n",
       " 'mu': tensor([3.1681, 1.1452, 0.8561, 2.7391, 4.9072, 0.9235, 1.7309, 3.3850, 3.1573,\n",
       "         1.9340, 1.1223, 3.7053, 2.5473, 1.0130, 4.0680, 3.1382, 0.8072, 5.8378,\n",
       "         3.6984, 4.7113, 0.9569, 3.3231, 2.8319, 1.8633, 3.4147, 3.6188, 4.0592,\n",
       "         4.9547, 4.1552, 2.6721, 1.8739, 3.9222]),\n",
       " 'alpha': tensor([71.9400, 79.7000, 73.5800, 60.3800, 75.1900, 83.8000, 80.2200, 84.0200,\n",
       "         74.1100, 75.2100, 68.1300, 78.9000, 69.2400, 70.0800, 84.7900, 61.4100,\n",
       "         86.6700, 74.5400, 73.6000, 81.2800, 86.0300, 82.3000, 73.9600, 80.4000,\n",
       "         80.4000, 74.5600, 77.4900, 66.8100, 82.3900, 64.8000, 84.7100, 52.3200]),\n",
       " 'homo': tensor([-6.5525, -6.9362, -5.9239, -6.4709, -5.7062, -6.2695, -6.9226, -6.6151,\n",
       "         -6.5035, -6.2586, -6.4491, -7.2736, -7.5212, -7.1185, -7.3580, -6.5743,\n",
       "         -6.1770, -7.1974, -7.1103, -6.4382, -6.5634, -6.6042, -6.5062, -6.6260,\n",
       "         -6.8246, -6.5226, -6.7375, -7.4722, -6.4763, -6.5906, -6.5471, -7.6464]),\n",
       " 'lumo': tensor([ 0.0354,  0.5225,  0.6014,  2.0517, -0.8408,  0.3456,  2.2477,  0.7510,\n",
       "         -0.5279,  0.8762,  2.2341,  0.4218,  0.5143, -1.3687,  1.0123,  0.4054,\n",
       "          1.3823, -0.9197,  0.2830,  0.1796,  2.2123, -0.4708, -0.0735,  1.3660,\n",
       "          0.9742,  1.6164, -1.4395, -0.8027, -0.3238, -0.5796,  2.0436, -2.5633]),\n",
       " 'gap': tensor([6.5852, 7.4559, 6.5253, 8.5253, 4.8654, 6.6178, 9.1702, 7.3661, 5.9756,\n",
       "         7.1321, 8.6832, 7.6981, 8.0355, 5.7498, 8.3702, 6.9770, 7.5593, 6.2777,\n",
       "         7.3933, 6.6178, 8.7757, 6.1334, 6.4328, 7.9920, 7.7988, 8.1389, 5.2981,\n",
       "         6.6695, 6.1525, 6.0110, 8.5906, 5.0831]),\n",
       " 'r2': tensor([1035.1259, 1781.0503,  917.2986,  660.9969, 1151.0081, 1120.2510,\n",
       "         1032.4139, 1996.7249, 1062.9397, 1331.8409,  953.7030, 1612.6522,\n",
       "         1047.5745, 1105.8785, 2149.3003,  794.6251, 1211.7189, 1932.9769,\n",
       "         1830.6375, 1262.2195, 1247.4117, 1285.8082,  956.0923, 1061.7921,\n",
       "         1085.2928, 1223.4642, 1125.9265,  928.4176, 1820.1105,  814.9319,\n",
       "         1226.1648,  814.2843]),\n",
       " 'zpve': tensor([3706.7644, 4240.5703, 3393.6155, 3767.2004, 3082.4531, 4948.2568,\n",
       "         5077.4565, 4585.1753, 4345.7969, 4034.6343, 4153.5752, 4284.2173,\n",
       "         3428.5549, 2879.2112, 5223.7998, 3245.5854, 4843.0581, 4235.5635,\n",
       "         4293.1699, 4646.1021, 5582.7456, 4335.9189, 3752.6426, 4336.2456,\n",
       "         4718.7290, 4956.3662, 3410.6770, 2444.3186, 4211.7808, 3564.8567,\n",
       "         5616.0791, 1622.1532]),\n",
       " 'U0': tensor([-11477.4600, -11509.1914, -10901.7324,  -8864.2812, -12465.8125,\n",
       "         -10532.8672, -10533.7021, -10970.0410, -11511.6064, -11845.4365,\n",
       "         -10473.4473, -11406.5752, -11915.2861, -10305.6504, -11003.4150,\n",
       "         -10879.1719, -10532.3047, -12522.8184, -12522.1768, -10866.8643,\n",
       "         -10565.1660, -10500.9170, -11476.6230, -10499.1602, -10970.5400,\n",
       "         -12554.4688, -10905.1953, -11308.2832, -11510.9814, -10442.6621,\n",
       "         -10566.1289, -12478.0625]),\n",
       " 'U': tensor([-11477.2461, -11508.9170, -10901.5459,  -8864.1104, -12465.5957,\n",
       "         -10532.6250, -10533.5088, -10969.7510, -11511.3838, -11845.1836,\n",
       "         -10473.2227, -11406.2998, -11915.0830, -10305.4219, -11003.1123,\n",
       "         -10878.9775, -10532.0127, -12522.5352, -12521.9189, -10866.5996,\n",
       "         -10564.9102, -10500.6943, -11476.4404, -10498.9414, -10970.3271,\n",
       "         -12554.2100, -10904.9844, -11308.0986, -11510.6758, -10442.4717,\n",
       "         -10565.8848, -12477.9004]),\n",
       " 'H': tensor([-11477.2207, -11508.8916, -10901.5205,  -8864.0850, -12465.5703,\n",
       "         -10532.6006, -10533.4834, -10969.7256, -11511.3584, -11845.1582,\n",
       "         -10473.1973, -11406.2744, -11915.0576, -10305.3965, -11003.0859,\n",
       "         -10878.9521, -10531.9873, -12522.5098, -12521.8936, -10866.5732,\n",
       "         -10564.8848, -10500.6689, -11476.4150, -10498.9160, -10970.3008,\n",
       "         -12554.1846, -10904.9590, -11308.0723, -11510.6504, -10442.4463,\n",
       "         -10565.8584, -12477.8750]),\n",
       " 'G': tensor([-11478.3682, -11510.1777, -10902.5801,  -8865.0928, -12466.6992,\n",
       "         -10533.7764, -10534.5576, -10971.0508, -11512.5088, -11846.3857,\n",
       "         -10474.3301, -11407.5488, -11916.1553, -10306.5586, -11004.4355,\n",
       "         -10880.0225, -10533.2441, -12523.8291, -12523.1465, -10867.8545,\n",
       "         -10566.0938, -10501.8203, -11477.4688, -10500.0371, -10971.4150,\n",
       "         -12555.4053, -10906.0723, -11309.1367, -11512.0283, -10443.5059,\n",
       "         -10567.0400, -12478.8896]),\n",
       " 'Cv': tensor([29.6520, 35.3420, 27.5730, 24.0810, 29.7160, 34.5180, 29.4500, 36.9220,\n",
       "         30.8290, 32.8320, 30.5990, 35.2830, 28.3330, 29.6520, 38.3310, 27.1010,\n",
       "         40.6390, 35.2230, 33.0380, 34.6890, 35.8430, 31.2660, 26.4690, 32.0290,\n",
       "         31.1100, 35.8130, 29.5810, 25.7390, 37.9730, 27.4900, 34.9350, 21.8800]),\n",
       " 'omega1': tensor([3799.8867, 3501.8369, 3502.1118, 3498.0559, 3662.3330, 3226.0315,\n",
       "         3142.2229, 3507.1431, 3126.2388, 3806.9229, 3791.2871, 3512.3567,\n",
       "         3245.5857, 3598.5198, 3150.2070, 3807.3684, 3792.3599, 3107.8630,\n",
       "         3147.0596, 3655.3093, 3126.9951, 3212.1155, 3192.7886, 3505.4443,\n",
       "         3458.2961, 3826.4861, 3778.7798, 3249.3621, 3811.4312, 3706.3914,\n",
       "         3095.2744, 3235.4504]),\n",
       " 'zpve_thermo': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64),\n",
       " 'U0_thermo': tensor([-419.0587, -420.0593, -398.0778, -323.3848, -455.7058, -383.8420,\n",
       "         -383.8420, -400.0788, -420.0593, -432.5525, -382.2125, -416.3157,\n",
       "         -435.2956, -376.4678, -401.0794, -397.4488, -383.8420, -457.2771,\n",
       "         -457.2771, -396.3352, -384.8426, -382.8415, -419.0587, -382.8415,\n",
       "         -400.0788, -458.2776, -398.0778, -413.3140, -420.0593, -381.2120,\n",
       "         -384.8426, -456.8194], dtype=torch.float64),\n",
       " 'U_thermo': tensor([-419.0347, -420.0324, -398.0551, -323.3621, -455.6846, -383.8123,\n",
       "         -383.8123, -400.0505, -420.0324, -432.5270, -382.1870, -416.2888,\n",
       "         -435.2729, -376.4480, -401.0482, -397.4275, -383.8123, -457.2502,\n",
       "         -457.2502, -396.3069, -384.8100, -382.8146, -419.0347, -382.8146,\n",
       "         -400.0505, -458.2479, -398.0551, -413.2956, -420.0324, -381.1893,\n",
       "         -384.8100, -456.8052], dtype=torch.float64),\n",
       " 'H_thermo': tensor([-419.0186, -420.0144, -398.0400, -323.3470, -455.6704, -383.7925,\n",
       "         -383.7925, -400.0316, -420.0144, -432.5100, -382.1700, -416.2708,\n",
       "         -435.2578, -376.4347, -401.0275, -397.4134, -383.7925, -457.2322,\n",
       "         -457.2322, -396.2880, -384.7883, -382.7966, -419.0186, -382.7966,\n",
       "         -400.0316, -458.2281, -398.0400, -413.2833, -420.0144, -381.1742,\n",
       "         -384.7883, -456.7958], dtype=torch.float64),\n",
       " 'G_thermo': tensor([-419.2757, -420.2976, -398.2841, -323.5834, -455.9024, -384.1012,\n",
       "         -384.1012, -400.3278, -420.2976, -432.7812, -382.4362, -416.5545,\n",
       "         -435.5024, -376.6495, -401.3497, -397.6410, -384.1012, -457.5158,\n",
       "         -457.5158, -396.5848, -385.1230, -383.0793, -419.2757, -383.0793,\n",
       "         -400.3278, -458.5376, -398.2841, -413.4889, -420.2976, -381.4144,\n",
       "         -385.1230, -456.9586], dtype=torch.float64),\n",
       " 'Cv_thermo': tensor([50.6770, 56.6390, 47.6960, 47.6960, 44.7150, 62.6010, 62.6010, 59.6200,\n",
       "         56.6390, 53.6580, 53.6580, 56.6390, 47.6960, 41.7340, 65.5820, 44.7150,\n",
       "         62.6010, 56.6390, 56.6390, 59.6200, 68.5630, 56.6390, 50.6770, 56.6390,\n",
       "         59.6200, 62.6010, 47.6960, 38.7530, 56.6390, 47.6960, 68.5630, 29.8100],\n",
       "        dtype=torch.float64),\n",
       " 'one_hot': tensor([[[False, False, False,  True, False],\n",
       "          [False,  True, False, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          ...,\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False]],\n",
       " \n",
       "         [[False,  True, False, False, False],\n",
       "          [False, False, False,  True, False],\n",
       "          [False,  True, False, False, False],\n",
       "          ...,\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False]],\n",
       " \n",
       "         [[False,  True, False, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          ...,\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[False, False, False,  True, False],\n",
       "          [False,  True, False, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          ...,\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False]],\n",
       " \n",
       "         [[False,  True, False, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          ...,\n",
       "          [ True, False, False, False, False],\n",
       "          [ True, False, False, False, False],\n",
       "          [ True, False, False, False, False]],\n",
       " \n",
       "         [[False, False, False, False,  True],\n",
       "          [False,  True, False, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          ...,\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False]]]),\n",
       " 'atom_mask': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True, False, False, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True, False, False, False, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "          False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False]]),\n",
       " 'edge_mask': tensor([[False],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         ...,\n",
       "         [False],\n",
       "         [False],\n",
       "         [False]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confirmed hypotesis:\n",
    "The .get_databatch() function returns a dictionary for 32 molecules (batch size = 32). \n",
    "The biggest molecule in the batch has 23 total atoms (heavy + hydrogens): all molecules have been padded to reach 23 atoms. \n",
    "Padded atoms can be recognized by the \"charges\" tensor where they have 0, by the \"one_hot\" where they have all False, and by the \"atom_mask\".\n",
    "\n",
    "The dictionary has the following relevant keys:\n",
    "- num_atoms : number of TOTAL atoms (heavy + hydrogens). SHAPE: [32]\n",
    "- charges : this is indeeed the ATOMIC NUMBER, from which we can retrieve the atom type. 0 is for padded atoms. SHAPE: [32, 23, 1]\n",
    "- positions : 3d coordinates of each atom. SHAPE: [32, 23, 3] == [N molecules, N atoms per mol (after padding), 3]\n",
    "- index: maybe is the number (index) of the molecule in the entire dataset\n",
    "- one_hot: Bool torch tensor built upon what they call \"atom_encoder\" which is indeed a vocabulary. This is the bool version of the one hot encoding (instead of having [1,0,0] you have [True, False, False] for each atom; padded atom have a tensor full of False). SHAPE: [32, 23, 5] == [N molecules, N atoms per mol (after padding), len(vocabulary)]\n",
    "- atom mask: Bool torch tensor that tells which atoms for each molecule exist (True) and which are padded atoms (False). SHAPE: [32, 23] \n",
    "- edge mask: Bool torch tensor which tells what edges exist. It has shape [23 * 23 * 32 , 1], which means that each molecule is reprsented as a FC graph. The masked edges are self loops and edges that include at least one padded node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_mask = batch[\"edge_mask\"]\n",
    "edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_mask[:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_mask[23:46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
